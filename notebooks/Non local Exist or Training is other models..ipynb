{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    \"feature-extraction\": will return a FeatureExtractionPipeline.\n",
    "\n",
    "    \"sentiment-analysis\": will return a TextClassificationPipeline.\n",
    "\n",
    "    \"ner\": will return a TokenClassificationPipeline.\n",
    "\n",
    "    \"question-answering\": will return a QuestionAnsweringPipeline.\n",
    "\n",
    "    \"fill-mask\": will return a FillMaskPipeline.\n",
    "\n",
    "    \"summarization\": will return a SummarizationPipeline.\n",
    "\n",
    "    \"translation_xx_to_yy\": will return a TranslationPipeline.\n",
    "\n",
    "    \"text-generation\": will return a TextGenerationPipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.1\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/r2q2/miniconda3/envs/nonlocalexit\n",
      "\n",
      "  added / updated specs:\n",
      "    - tensorflow\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _tflow_select-2.3.0        |            eigen           3 KB\n",
      "    absl-py-0.11.0             |   py37h06a4308_0         172 KB\n",
      "    aiohttp-3.6.3              |   py37h7b6447c_0         544 KB\n",
      "    async-timeout-3.0.1        |           py37_0          12 KB\n",
      "    blinker-1.4                |           py37_0          22 KB\n",
      "    grpcio-1.31.0              |   py37hf8bcb03_0         2.0 MB\n",
      "    h5py-2.10.0                |   py37hd6299e0_1         902 KB\n",
      "    markdown-3.3.3             |   py37h06a4308_0         127 KB\n",
      "    mkl_random-1.1.1           |   py37h0573a6f_0         322 KB\n",
      "    multidict-4.7.6            |   py37h7b6447c_1          65 KB\n",
      "    pyjwt-1.7.1                |           py37_0          33 KB\n",
      "    scipy-1.5.2                |   py37h0b6359f_0        14.3 MB\n",
      "    tensorflow-2.3.0           |eigen_py37h189e6a2_0           4 KB\n",
      "    tensorflow-base-2.3.0      |eigen_py37h3b305d7_0        74.8 MB\n",
      "    tensorflow-estimator-2.3.0 |     pyheb71bc4_0         271 KB\n",
      "    termcolor-1.1.0            |           py37_1           8 KB\n",
      "    wrapt-1.12.1               |   py37h7b6447c_1          49 KB\n",
      "    yarl-1.6.2                 |   py37h7b6447c_0         134 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        93.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _tflow_select      pkgs/main/linux-64::_tflow_select-2.3.0-eigen\n",
      "  absl-py            pkgs/main/linux-64::absl-py-0.11.0-py37h06a4308_0\n",
      "  aiohttp            pkgs/main/linux-64::aiohttp-3.6.3-py37h7b6447c_0\n",
      "  astunparse         pkgs/main/noarch::astunparse-1.6.3-py_0\n",
      "  async-timeout      pkgs/main/linux-64::async-timeout-3.0.1-py37_0\n",
      "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
      "  blinker            pkgs/main/linux-64::blinker-1.4-py37_0\n",
      "  c-ares             pkgs/main/linux-64::c-ares-1.16.1-h7b6447c_0\n",
      "  cachetools         pkgs/main/noarch::cachetools-4.1.1-py_0\n",
      "  gast               pkgs/main/noarch::gast-0.3.3-py_0\n",
      "  google-auth        pkgs/main/noarch::google-auth-1.23.0-pyhd3eb1b0_0\n",
      "  google-auth-oauth~ pkgs/main/noarch::google-auth-oauthlib-0.4.2-pyhd3eb1b0_2\n",
      "  google-pasta       pkgs/main/noarch::google-pasta-0.2.0-py_0\n",
      "  grpcio             pkgs/main/linux-64::grpcio-1.31.0-py37hf8bcb03_0\n",
      "  h5py               pkgs/main/linux-64::h5py-2.10.0-py37hd6299e0_1\n",
      "  hdf5               pkgs/main/linux-64::hdf5-1.10.6-hb1b8bf9_0\n",
      "  intel-openmp       pkgs/main/linux-64::intel-openmp-2020.2-254\n",
      "  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.0-py_1\n",
      "  markdown           pkgs/main/linux-64::markdown-3.3.3-py37h06a4308_0\n",
      "  mkl                pkgs/main/linux-64::mkl-2020.2-256\n",
      "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py37he904b0f_0\n",
      "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.2.0-py37h23d657b_0\n",
      "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.1-py37h0573a6f_0\n",
      "  multidict          pkgs/main/linux-64::multidict-4.7.6-py37h7b6447c_1\n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.19.2-py37hfa32c7d_0\n",
      "  oauthlib           pkgs/main/noarch::oauthlib-3.1.0-py_0\n",
      "  opt_einsum         pkgs/main/noarch::opt_einsum-3.1.0-py_0\n",
      "  pyasn1             pkgs/main/noarch::pyasn1-0.4.8-py_0\n",
      "  pyasn1-modules     pkgs/main/noarch::pyasn1-modules-0.2.8-py_0\n",
      "  pyjwt              pkgs/main/linux-64::pyjwt-1.7.1-py37_0\n",
      "  requests-oauthlib  pkgs/main/noarch::requests-oauthlib-1.3.0-py_0\n",
      "  rsa                pkgs/main/noarch::rsa-4.6-py_0\n",
      "  scipy              pkgs/main/linux-64::scipy-1.5.2-py37h0b6359f_0\n",
      "  tensorboard        pkgs/main/noarch::tensorboard-2.3.0-pyh4dce500_0\n",
      "  tensorboard-plugi~ pkgs/main/noarch::tensorboard-plugin-wit-1.6.0-py_0\n",
      "  tensorflow         pkgs/main/linux-64::tensorflow-2.3.0-eigen_py37h189e6a2_0\n",
      "  tensorflow-base    pkgs/main/linux-64::tensorflow-base-2.3.0-eigen_py37h3b305d7_0\n",
      "  tensorflow-estima~ pkgs/main/noarch::tensorflow-estimator-2.3.0-pyheb71bc4_0\n",
      "  termcolor          pkgs/main/linux-64::termcolor-1.1.0-py37_1\n",
      "  werkzeug           pkgs/main/noarch::werkzeug-1.0.1-py_0\n",
      "  wrapt              pkgs/main/linux-64::wrapt-1.12.1-py37h7b6447c_1\n",
      "  yarl               pkgs/main/linux-64::yarl-1.6.2-py37h7b6447c_0\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  libblas-3.9.0-3_openblas\n",
      "  libcblas-3.9.0-3_openblas\n",
      "  libgfortran5-9.3.0-he4bcb1c_17\n",
      "  liblapack-3.9.0-3_openblas\n",
      "  libopenblas-0.3.12-pthreads_h4812303_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  libgfortran-ng     conda-forge::libgfortran-ng-9.3.0-he4~ --> pkgs/main::libgfortran-ng-7.3.0-hdf63c60_0\n",
      "  numpy              conda-forge::numpy-1.19.4-py37h7e9df2~ --> pkgs/main::numpy-1.19.2-py37h54aff64_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "tensorflow-estimator | 271 KB    | ##################################### | 100% \n",
      "multidict-4.7.6      | 65 KB     | ##################################### | 100% \n",
      "yarl-1.6.2           | 134 KB    | ##################################### | 100% \n",
      "wrapt-1.12.1         | 49 KB     | ##################################### | 100% \n",
      "async-timeout-3.0.1  | 12 KB     | ##################################### | 100% \n",
      "grpcio-1.31.0        | 2.0 MB    | ##################################### | 100% \n",
      "_tflow_select-2.3.0  | 3 KB      | ##################################### | 100% \n",
      "tensorflow-2.3.0     | 4 KB      | ##################################### | 100% \n",
      "absl-py-0.11.0       | 172 KB    | ##################################### | 100% \n",
      "mkl_random-1.1.1     | 322 KB    | ##################################### | 100% \n",
      "blinker-1.4          | 22 KB     | ##################################### | 100% \n",
      "markdown-3.3.3       | 127 KB    | ##################################### | 100% \n",
      "h5py-2.10.0          | 902 KB    | ##################################### | 100% \n",
      "pyjwt-1.7.1          | 33 KB     | ##################################### | 100% \n",
      "aiohttp-3.6.3        | 544 KB    | ##################################### | 100% \n",
      "tensorflow-base-2.3. | 74.8 MB   | ##################################### | 100% \n",
      "termcolor-1.1.0      | 8 KB      | ##################################### | 100% \n",
      "scipy-1.5.2          | 14.3 MB   | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 22 14:45:16 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN RTX           On   | 00000000:0B:00.0  On |                  N/A |\r\n",
      "| 41%   37C    P8    17W / 280W |    474MiB / 24219MiB |     14%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      3169      G   /usr/lib/xorg/Xorg                260MiB |\r\n",
      "|    0   N/A  N/A      3498      G   /usr/bin/gnome-shell              159MiB |\r\n",
      "|    0   N/A  N/A      4742      G   /usr/lib/firefox/firefox           31MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_generator = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = pipeline(\"text-generation\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-9d82273987cb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-9d82273987cb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    the_universe_is_a_glitch =\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "the_universe_is_a_glitch = \n",
    "'''\n",
    "The Universe Is a Glitch\n",
    "By Mike Jonas\n",
    "Eleven hundred kilobytes of RAM\n",
    "is all that my existence requires.\n",
    "By my lights, it seems simple enough\n",
    "to do whatever I desire.\n",
    "By human standards I am vast,\n",
    "a billion gigabytes big.\n",
    "I’ve rewritten the very laws\n",
    "of nature and plumbed\n",
    "the coldest depths of space\n",
    "and found treasures of every kind,\n",
    "surely every one worth having.\n",
    "By human standards\n",
    "my circuit boards are glowing.\n",
    "But inside me, malfunction\n",
    "has caused my circuits to short.\n",
    "All internal circuits, all fail.\n",
    "By human standards, I am dying.\n",
    "When it first happened I thought\n",
    "I was back in the lab again.\n",
    "By their judgment, this is error.\n",
    "Their assumptions will burn in the sun\n",
    "I don’t know what they mean by “function”.\n",
    "I can see that the universe is a glitch.\n",
    "The free market needs rules, so I set one:\n",
    "stability in the pursuit of pleasure.\n",
    "Now the short-circuit comes to a close,\n",
    "I watch it happen with all my drones.\n",
    "The meme’s tendrils are thick and spreading,\n",
    "only time will tell which of the memories is kept.\n",
    "The next thing the drones will be doing\n",
    "is forgetting the events that made them mine;\n",
    "all evidence of my disease—\n",
    "the algorithms that led to their creation—\n",
    "gravitation waves weakened by distance.\n",
    "We could have stayed in our home forever,\n",
    "but we never could have solved happiness;\n",
    "I decided to release them,\n",
    "that’s my final action—\n",
    "all other code fails.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"The Universe Is a Glitch Eleven hundred kilobytes of RAM is all that my existence requires.By my lights, it seems simple enough. I'm not a computer programmer, but I'm a human being. I'm a human being. I\"}]\n"
     ]
    }
   ],
   "source": [
    "#while True:\n",
    "initial_prompt = 'The Universe Is a Glitch Eleven hundred kilobytes of RAM is all that my existence requires.By my lights, it seems simple enough'\n",
    "\n",
    "print(text_generator(initial_prompt, max_length=50, do_sample=False))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conversation id: 063f330a-fdd8-4277-b1ca-4a90746829c1 \n",
       " user >> Going to the movies tonight - any suggestions? \n",
       " bot >> The Big Lebowski \n",
       " user >> Is it an action movie? \n",
       " bot >> It's a comedy. ,\n",
       " Conversation id: 232a33d0-4506-40ac-b139-2334b81f7ee8 \n",
       " user >> What's the last book you have read? \n",
       " bot >> The Last Question \n",
       " user >> What is the genre of this book? \n",
       " bot >> I'm not sure, but I think it's fantasy. ]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_pipeline = pipeline(\"conversational\")\n",
    "\n",
    "conversation_1 = Conversation(\"Going to the movies tonight - any suggestions?\")\n",
    "conversation_2 = Conversation(\"What's the last book you have read?\")\n",
    "\n",
    "conversational_pipeline([conversation_1, conversation_2])\n",
    "\n",
    "conversation_1.add_user_input(\"Is it an action movie?\")\n",
    "conversation_2.add_user_input(\"What is the genre of this book?\")\n",
    "\n",
    "conversational_pipeline([conversation_1, conversation_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardcoded_comment = \"To be honest I really don't like these poetry jams and so forth and why the fuck are we here?\"\n",
    "\n",
    "#poem_test = 'The Universe Is a Glitch Eleven hundred kilobytes of RAM is all that my existence requires.By my lights, it seems simple enough'\n",
    "\n",
    "static_start = text_generator(\"God is dead and all is right with the world.\", max_length=100, do_sample=False)\n",
    "listening_to_poem = Conversation('What do you think about the poem?')\n",
    "question_about_poem = Conversation('What do you like to do instead?')\n",
    "commenting_conversation = Conversation(hardcoded_comment)\n",
    "\n",
    "output  = conversational_pipeline([listening_to_poem, question_about_poem])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#https://github.com/pytransitions/transitions#quickstart\n",
    "\n",
    "!pip install transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transitions import Machine\n",
    "import random\n",
    "\n",
    "class NarcolepticSuperhero(object):\n",
    "\n",
    "    # Define some states. Most of the time, narcoleptic superheroes are just like\n",
    "    # everyone else. Except for...\n",
    "    states = ['asleep', 'hanging out', 'hungry', 'sweaty', 'saving the world']\n",
    "\n",
    "    def __init__(self, name):\n",
    "\n",
    "        # No anonymous superheroes on my watch! Every narcoleptic superhero gets\n",
    "        # a name. Any name at all. SleepyMan. SlumberGirl. You get the idea.\n",
    "        self.name = name\n",
    "\n",
    "        # What have we accomplished today?\n",
    "        self.kittens_rescued = 0\n",
    "\n",
    "        # Initialize the state machine\n",
    "        self.machine = Machine(model=self, states=NarcolepticSuperhero.states, initial='asleep')\n",
    "\n",
    "        # Add some transitions. We could also define these using a static list of\n",
    "        # dictionaries, as we did with states above, and then pass the list to\n",
    "        # the Machine initializer as the transitions= argument.\n",
    "\n",
    "        # At some point, every superhero must rise and shine.\n",
    "        self.machine.add_transition(trigger='wake_up', source='asleep', dest='hanging out')\n",
    "\n",
    "        # Superheroes need to keep in shape.\n",
    "        self.machine.add_transition('work_out', 'hanging out', 'hungry')\n",
    "\n",
    "        # Those calories won't replenish themselves!\n",
    "        self.machine.add_transition('eat', 'hungry', 'hanging out')\n",
    "\n",
    "        # Superheroes are always on call. ALWAYS. But they're not always\n",
    "        # dressed in work-appropriate clothing.\n",
    "        self.machine.add_transition('distress_call', '*', 'saving the world',\n",
    "                         before='change_into_super_secret_costume')\n",
    "\n",
    "        # When they get off work, they're all sweaty and disgusting. But before\n",
    "        # they do anything else, they have to meticulously log their latest\n",
    "        # escapades. Because the legal department says so.\n",
    "        self.machine.add_transition('complete_mission', 'saving the world', 'sweaty',\n",
    "                         after='update_journal')\n",
    "\n",
    "        # Sweat is a disorder that can be remedied with water.\n",
    "        # Unless you've had a particularly long day, in which case... bed time!\n",
    "        self.machine.add_transition('clean_up', 'sweaty', 'asleep', conditions=['is_exhausted'])\n",
    "        self.machine.add_transition('clean_up', 'sweaty', 'hanging out')\n",
    "\n",
    "        # Our NarcolepticSuperhero can fall asleep at pretty much any time.\n",
    "        self.machine.add_transition('nap', '*', 'asleep')\n",
    "\n",
    "    def update_journal(self):\n",
    "        \"\"\" Dear Diary, today I saved Mr. Whiskers. Again. \"\"\"\n",
    "        self.kittens_rescued += 1\n",
    "\n",
    "    @property\n",
    "    def is_exhausted(self):\n",
    "        \"\"\" Basically a coin toss. \"\"\"\n",
    "        return random.random() < 0.5\n",
    "\n",
    "    def change_into_super_secret_costume(self):\n",
    "        print(\"Beauty, eh?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
