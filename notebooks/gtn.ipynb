{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtn\n",
      "  Downloading gtn-0.0.0.tar.gz (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gtn\n",
      "  Building wheel for gtn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gtn: filename=gtn-0.0.0-cp38-cp38-macosx_11_0_x86_64.whl size=517107 sha256=264868212547fc568be5ed19ab970117329faa0f60e29f877ec1fbda46f0f23a\n",
      "  Stored in directory: /Users/r2q2/Library/Caches/pip/wheels/e1/8e/fa/f19e40c5750bc992a5214c96123a1c19a92082fe6d45605da2\n",
      "Successfully built gtn\n",
      "Installing collected packages: gtn\n",
      "Successfully installed gtn-0.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTNLossFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    A minimal example of adding a custom loss function built with GTN graphs to\n",
    "    PyTorch.\n",
    "\n",
    "    The example is a sequence criterion which computes a loss between a\n",
    "    frame-level input and a token-level target. The tokens in the target can\n",
    "    align to one or more frames in the input.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, targets):\n",
    "        B, T, C = inputs.shape\n",
    "        losses = [None] * B\n",
    "        emissions_graphs = [None] * B\n",
    "\n",
    "        # Move data to the host as GTN operations run on the CPU:\n",
    "        device = inputs.device\n",
    "        inputs = inputs.cpu()\n",
    "        targets = targets.cpu()\n",
    "\n",
    "        # Compute the loss for the b-th example:\n",
    "        def forward_single(b):\n",
    "            emissions = gtn.linear_graph(T, C, inputs.requires_grad)\n",
    "            # *NB* A reference to the `data` should be held explicitly when\n",
    "            # using `data_ptr()` otherwise the memory may be claimed before the\n",
    "            # weights are set. For example, the following is undefined and will\n",
    "            # likely cause serious issues:\n",
    "            #   `emissions.set_weights(inputs[b].contiguous().data_ptr())`\n",
    "            data = inputs[b].contiguous()\n",
    "            emissions.set_weights(data.data_ptr())\n",
    "\n",
    "            target = GTNLossFunction.make_target_graph(targets[b])\n",
    "\n",
    "            # Score the target:\n",
    "            target_score = gtn.forward_score(gtn.intersect(target, emissions))\n",
    "\n",
    "            # Normalization term:\n",
    "            norm = gtn.forward_score(emissions)\n",
    "\n",
    "            # Compute the loss:\n",
    "            loss = gtn.subtract(norm, target_score)\n",
    "\n",
    "            # We need the save the `loss` graph to call `gtn.backward` and we\n",
    "            # need the `emissions` graph to access the gradients:\n",
    "            losses[b] = loss\n",
    "            emissions_graphs[b] = emissions\n",
    "\n",
    "        # Compute the loss in parallel over the batch:\n",
    "        gtn.parallel_for(forward_single, range(B))\n",
    "\n",
    "        # Save some graphs and other data for backward:\n",
    "        ctx.auxiliary_data = (losses, emissions_graphs, inputs.shape)\n",
    "\n",
    "        # Put losses back in a torch tensor and move them  back to the device:\n",
    "        return torch.tensor([l.item() for l in losses]).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
