{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of facebookresearch_semi-supervised-ImageNet1K-models_resnext.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3d7aZUHxDS5"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# Semi-supervised and semi-weakly supervised ImageNet Models\n",
        "\n",
        "*Author: Facebook AI*\n",
        "\n",
        "**ResNet and ResNext models introduced in the \"Billion scale semi-supervised learning for image classification\" paper**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/ssl-image.png\" alt=\"alt\" width=\"50%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8vguzqYxDS8",
        "outputId": "11ef3032-9c70-4357-865e-49681399b844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# === SEMI-WEAKLY SUPERVISED MODELSP RETRAINED WITH 940 HASHTAGGED PUBLIC CONTENT ===\n",
        "model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl')\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet50_swsl')\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext50_32x4d_swsl')\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x4d_swsl')\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x8d_swsl')\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x16d_swsl')\n",
        "# ================= SEMI-SUPERVISED MODELS PRETRAINED WITH YFCC100M ==================\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_ssl')\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet50_ssl')\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext50_32x4d_ssl')\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x4d_ssl')\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x8d_ssl')\n",
        "# model = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnext101_32x16d_ssl')\n",
        "model.eval()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YppTlZp3xDTT"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "Here's a sample execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySjVtBjZxDTV"
      },
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l89ooH55xDTb",
        "outputId": "095c08cf-e4e5-4b9a-9d05-20e7670877cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "print(torch.nn.functional.softmax(output[0], dim=0))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 7.4253e-01, -1.4604e+00, -1.9296e+00, -3.7738e+00, -1.1951e+00,\n",
            "        -1.7112e+00, -9.8436e-01,  1.4549e+00,  4.2586e+00, -3.2119e+00,\n",
            "        -2.2241e+00, -6.3297e-01, -8.5228e-01, -1.0632e+00,  5.3717e-02,\n",
            "        -2.6708e+00, -2.2127e+00,  7.1043e-01,  7.3210e-01,  5.1914e-01,\n",
            "        -7.4688e-01, -1.0444e+00, -5.1885e-01,  3.6073e-01, -7.2254e-01,\n",
            "         4.8398e-01,  1.4409e-01,  1.2153e+00,  5.3841e-01,  8.0024e-01,\n",
            "        -1.0598e+00, -2.3192e+00, -5.9817e-01, -1.3603e+00, -7.2159e-01,\n",
            "         1.2465e+00,  3.5991e+00,  3.3691e+00, -1.4424e+00,  1.4266e-01,\n",
            "        -7.3418e-01, -1.8353e+00,  1.3662e-01,  8.2530e-01,  3.5589e-01,\n",
            "        -7.7401e-01,  1.9756e-01, -8.3585e-01,  1.1053e-01, -3.5271e-01,\n",
            "        -1.3412e-01, -4.0866e-01,  9.7658e-01,  2.3028e-01,  8.6073e-01,\n",
            "        -3.8138e-01,  4.4516e-01, -4.7939e-01, -1.8549e+00, -3.2430e-01,\n",
            "         3.4503e-01, -1.0864e+00,  1.8398e-02,  2.0630e-01,  4.0546e-02,\n",
            "        -1.0448e+00, -6.8809e-01, -3.2967e-02, -7.5990e-01, -3.1701e+00,\n",
            "        -2.0332e+00, -1.8276e+00, -2.1414e+00, -1.8956e+00, -2.8241e+00,\n",
            "        -3.0173e+00, -3.3768e+00, -1.6174e+00,  1.2272e+00, -3.0596e-01,\n",
            "         6.1635e-01,  3.1424e+00,  2.2798e+00,  1.9870e-01,  1.2011e+00,\n",
            "         4.8082e-01,  1.0508e+00, -1.0345e+00, -1.8484e+00,  2.0184e+00,\n",
            "        -8.1197e-01, -1.5048e+00, -2.4246e+00, -1.1466e-01, -1.5918e+00,\n",
            "        -2.6017e+00,  4.8348e-01, -1.7799e+00, -7.3115e-01, -2.0430e-01,\n",
            "         1.8388e+00, -4.7226e-01,  2.9786e-01, -2.0553e-01,  4.7028e+00,\n",
            "        -8.0979e-01,  1.6893e+00, -1.9803e+00,  2.7020e-02, -2.1740e+00,\n",
            "        -1.2330e+00, -4.2645e+00,  9.0411e-01, -8.1374e-01,  2.7840e+00,\n",
            "        -3.2519e-01, -2.5459e+00, -6.4277e-01, -8.4007e-01, -1.6935e+00,\n",
            "        -1.2338e+00, -1.0787e+00,  4.3632e-02, -1.5602e+00,  2.0850e+00,\n",
            "        -1.6740e+00, -9.7173e-01,  3.2313e-01, -1.3797e+00,  1.1243e+00,\n",
            "        -1.1504e+00, -1.2348e+00,  7.7125e-01, -1.8623e+00,  8.2134e-01,\n",
            "         2.4714e-01, -9.7313e-01, -2.7414e-01, -1.3729e+00, -3.6336e-01,\n",
            "        -1.0088e+00, -1.6612e+00, -2.3906e+00,  1.0112e-01, -1.0557e+00,\n",
            "         2.3611e+00,  1.1553e+00, -2.6531e+00, -2.8815e+00,  5.1457e-02,\n",
            "        -2.5839e+00,  4.4785e+00,  4.7963e+00,  3.9658e+00,  4.5178e+00,\n",
            "        -3.5785e-02,  1.5491e-01,  7.2563e+00,  2.9260e-01, -5.8682e-01,\n",
            "         2.7846e+00, -2.7141e+00, -3.1089e+00, -1.6644e-01, -9.6568e-01,\n",
            "        -3.2254e+00, -1.0296e+00, -1.5561e+00,  4.2885e-01,  3.1386e+00,\n",
            "         2.6992e+00, -8.9385e-01, -1.1873e+00,  1.7648e+00,  3.9390e+00,\n",
            "         2.0778e+00, -1.0193e+00,  1.0229e+00, -1.2402e+00,  1.2649e+00,\n",
            "         2.0937e+00,  4.4226e-01, -1.7355e+00,  1.8543e+00,  8.5064e-01,\n",
            "         5.0451e+00,  6.3943e+00,  4.6710e-01,  1.8954e+00,  5.3440e-01,\n",
            "         4.2475e+00, -2.7810e+00,  4.2495e+00,  5.9261e+00,  3.8650e+00,\n",
            "        -3.2065e-01, -1.9140e-01,  2.2364e+00, -1.4614e-01,  4.4004e+00,\n",
            "         4.1410e+00,  1.3255e+00,  1.9148e+00,  7.8047e+00,  3.5009e+00,\n",
            "        -8.4417e-01, -6.3410e-02,  3.0737e+00, -5.4135e-01, -1.0674e+00,\n",
            "        -2.8417e+00, -1.8841e+00,  1.7051e+00,  3.1592e-01,  5.1111e-01,\n",
            "        -1.2025e-01,  4.4914e+00, -2.5762e-01,  6.9082e-01,  1.2580e+00,\n",
            "         1.6933e+00,  1.6750e+00,  7.4398e+00,  6.8114e+00,  7.0392e+00,\n",
            "        -7.7095e-02,  4.3468e+00,  1.5052e+00,  4.8527e+00,  5.4688e+00,\n",
            "         6.5009e+00,  7.3702e+00,  7.3848e+00,  3.8436e+00, -6.0544e-01,\n",
            "         3.6327e+00,  1.1562e+00, -6.3390e-01,  2.1783e-01,  1.8958e+00,\n",
            "         1.6149e+00,  2.1743e+00, -1.2615e+00, -1.2290e+00,  3.3388e+00,\n",
            "         3.9944e-01, -8.0048e-01,  1.9417e+00,  8.8677e+00,  7.2274e+00,\n",
            "         6.5189e+00,  8.3714e-01,  1.4847e+00, -8.4723e-01, -2.7374e+00,\n",
            "         3.6920e+00,  4.7514e+00,  9.0993e+00,  1.3807e+01,  1.1024e+01,\n",
            "         8.0562e+00,  9.6501e+00, -1.1850e+00,  5.0519e+00,  5.4903e+00,\n",
            "         2.3524e+00,  4.1207e+00,  3.4406e+00, -2.8016e-01,  5.1897e+00,\n",
            "         1.0185e+01,  3.2357e+00,  2.6773e+00,  2.2907e+00,  4.7716e+00,\n",
            "         1.2027e+00,  1.9711e+00,  3.8773e+00,  3.9650e+00,  1.1593e+01,\n",
            "         4.3653e+00,  1.8615e+00,  1.5962e+00,  5.6691e+00,  7.3057e-01,\n",
            "        -7.4479e-01, -1.6591e+00,  4.5811e+00, -3.4484e+00,  1.4014e+00,\n",
            "        -2.0937e+00,  1.4654e+00,  9.9250e-01,  1.2417e-01,  8.9901e-01,\n",
            "         4.5659e-01,  2.3607e+00,  1.8990e+00,  4.5208e-01, -1.5438e+00,\n",
            "        -3.3889e+00, -3.3636e-01, -1.6067e+00, -1.6582e+00, -1.5174e+00,\n",
            "        -8.8931e-01,  1.2904e-01, -1.7810e+00, -5.3279e+00, -2.4499e+00,\n",
            "        -8.6581e-01, -2.1535e+00, -2.6161e-01, -1.8739e+00,  2.2020e-01,\n",
            "        -3.0682e+00, -5.1503e-01, -1.5872e+00, -1.0225e+00, -3.6053e+00,\n",
            "        -2.9688e+00, -3.9485e+00, -3.2406e+00,  3.5718e-01,  2.2003e-01,\n",
            "        -1.2593e+00, -2.5568e+00, -1.5573e+00, -1.6760e+00, -6.2765e-01,\n",
            "         2.3213e+00,  3.3941e+00,  7.1818e+00,  2.9872e+00,  2.4991e+00,\n",
            "         2.3555e+00,  3.1630e+00,  2.0934e+00,  2.2229e+00, -3.5900e+00,\n",
            "        -1.9553e+00,  1.1522e+00,  4.4763e-02, -2.6247e+00, -2.6374e+00,\n",
            "        -1.1913e+00, -2.3959e+00, -3.6724e+00,  3.4346e-01, -2.0362e+00,\n",
            "        -5.6326e-01, -4.3697e+00, -4.1436e+00, -1.9945e+00, -2.5886e+00,\n",
            "         2.0253e+00,  4.7756e+00,  3.2942e+00,  4.9535e+00,  3.9079e+00,\n",
            "        -9.3276e-01,  5.8227e+00,  2.7480e+00,  7.9864e-01, -1.1056e+00,\n",
            "        -2.3424e+00, -2.4751e+00, -2.1679e+00,  1.8101e+00,  9.7509e-02,\n",
            "        -3.5022e-01,  1.2435e+00, -5.2085e-01,  1.7823e+00,  6.6755e-01,\n",
            "         1.0471e-02, -1.3887e+00,  2.9419e+00,  1.1241e+00, -7.1793e-01,\n",
            "         2.7543e+00, -9.4670e-01,  9.8333e-01,  2.4672e+00,  2.5382e+00,\n",
            "        -2.4782e+00, -2.7920e+00,  1.5002e+00,  1.8418e+00,  5.4123e-01,\n",
            "        -1.5024e+00,  1.1912e+00, -2.9751e+00, -2.2086e+00, -1.6149e+00,\n",
            "        -1.4102e+00, -2.0655e+00, -2.1740e+00, -8.6421e-01, -2.6529e+00,\n",
            "        -1.6714e+00,  1.2389e+00,  1.2158e-01, -2.0968e+00, -2.1484e+00,\n",
            "        -7.8831e-01, -1.6173e+00, -1.5111e+00,  1.3547e+00,  1.5062e+00,\n",
            "        -1.6921e-02, -2.0394e+00,  2.2931e+00,  2.7783e+00, -1.6042e+00,\n",
            "        -2.3592e+00,  3.5765e-01, -2.0554e+00, -8.4191e-02,  1.4738e+00,\n",
            "         2.0026e+00, -2.3763e+00, -1.7851e+00, -1.9452e+00, -5.5068e+00,\n",
            "        -1.7562e+00, -3.1794e-01,  4.3215e-01,  3.5886e+00,  2.4221e+00,\n",
            "        -3.1021e+00,  5.3252e-01, -1.0754e+00, -1.8724e+00, -1.0846e+00,\n",
            "         3.8309e-01, -9.6866e-01,  4.8153e-01, -2.1877e+00, -1.8636e-01,\n",
            "         3.5044e+00, -1.4949e-01, -1.8382e+00,  4.4548e-01, -1.8550e-01,\n",
            "         1.3816e-01, -3.9145e+00,  1.0046e+00,  4.6473e-01, -1.8175e+00,\n",
            "        -1.4093e+00, -1.5162e+00,  1.9665e+00, -1.5797e+00, -2.3677e+00,\n",
            "         1.3354e+00,  1.0583e+00,  2.0153e+00, -2.3377e-01, -2.9697e-01,\n",
            "         7.5515e-02, -9.9897e-01,  2.0787e+00,  2.8127e+00, -2.1880e+00,\n",
            "         4.8426e-02, -2.7219e+00, -4.6631e-01, -1.9730e+00,  1.0407e+00,\n",
            "        -2.1584e-01,  1.6484e+00,  2.1986e+00,  3.4544e-01, -1.6178e+00,\n",
            "        -7.3646e-01, -4.4440e+00, -1.5121e+00,  4.1986e-01, -6.3682e-01,\n",
            "        -2.0440e+00, -2.8560e+00, -2.7186e-02, -2.1411e+00, -2.0040e+00,\n",
            "        -1.6315e+00, -5.7818e-01,  1.2023e+00,  6.0350e-01,  2.0386e-01,\n",
            "         1.7051e+00,  1.6038e+00,  2.1803e-01, -7.4303e-01,  2.3587e-01,\n",
            "        -1.9163e+00,  2.4822e+00, -9.1163e-01, -4.0735e+00,  1.7005e+00,\n",
            "        -3.5475e+00,  1.9106e+00,  1.9148e+00, -1.5781e+00, -8.2002e-01,\n",
            "        -4.3642e-01, -1.0510e+00, -4.1514e-01,  3.0847e-01, -3.9343e+00,\n",
            "        -1.0121e+00, -5.8404e-01, -2.2194e+00, -1.8258e+00,  1.4445e+00,\n",
            "         1.3075e+00, -6.7627e-01, -2.3540e+00,  6.8215e-01,  1.0368e+00,\n",
            "        -3.1678e+00,  6.5545e-02,  3.5578e+00,  1.1671e+00, -1.2930e+00,\n",
            "        -2.0633e+00, -1.1575e+00, -5.6829e-01, -1.0410e+00,  1.7162e+00,\n",
            "         3.7971e-01, -1.3681e+00, -2.6570e+00, -1.5559e+00,  1.5756e+00,\n",
            "        -3.8110e+00, -2.9901e+00,  1.7468e-01, -2.2168e+00,  2.8177e+00,\n",
            "        -2.0731e+00, -1.3158e+00, -7.5184e-01,  2.0610e+00,  5.0246e-01,\n",
            "         2.0325e+00, -8.7044e-01, -3.9527e+00, -1.0393e+00, -2.0364e-01,\n",
            "        -3.9035e+00, -2.2286e+00,  2.7493e+00, -1.6357e+00, -2.5386e-01,\n",
            "        -2.3355e+00,  1.3740e-01, -4.3463e-01,  2.9171e-01,  4.2619e-01,\n",
            "         4.6691e-01, -7.5493e-01, -2.1686e+00, -1.2841e+00, -1.5809e+00,\n",
            "        -2.4321e+00, -2.5373e-01,  1.8362e+00,  5.2890e-01, -1.3765e+00,\n",
            "        -8.3867e-01, -3.4085e+00, -1.5726e+00, -1.5993e+00,  2.1732e+00,\n",
            "         1.0813e+00, -3.8365e+00, -7.8530e-01,  1.0399e-01, -6.9999e-01,\n",
            "         5.6904e-01, -3.0737e+00, -5.8228e-01, -1.1830e+00, -1.9345e+00,\n",
            "        -2.1435e+00, -1.5890e+00,  1.1868e+00,  2.5411e-01,  1.4701e+00,\n",
            "        -1.4404e+00,  5.7064e-01, -4.2941e+00,  4.0443e-01,  1.4783e+00,\n",
            "        -1.6399e+00,  3.1083e+00, -2.2103e+00,  4.1257e-01, -1.1842e+00,\n",
            "         1.5690e-01,  1.3536e-01, -1.6384e+00, -2.3111e+00, -2.4608e+00,\n",
            "        -2.6360e-01,  2.3148e-01,  1.0049e-01, -9.5497e-01, -1.3516e+00,\n",
            "         1.0130e+00,  1.8935e+00, -3.9375e+00, -2.6089e-01, -2.5725e+00,\n",
            "         9.0718e-02, -2.5702e+00, -1.6337e+00,  7.9619e-01, -2.9344e+00,\n",
            "        -1.9670e-01,  2.9540e+00,  2.3652e+00, -8.4059e-01, -3.7155e+00,\n",
            "        -2.3399e+00,  1.1636e+00, -8.9623e-01, -1.4590e+00, -1.5444e+00,\n",
            "         8.5835e-01, -1.3401e-01, -1.1084e+00, -1.7336e-01, -1.1266e+00,\n",
            "         4.1643e-01, -2.4407e+00,  1.6254e+00, -1.0127e+00, -4.2713e-01,\n",
            "         1.1107e+00,  1.5170e+00,  2.8978e-01, -2.0320e+00,  6.3689e-01,\n",
            "         5.3484e-01,  2.5802e+00, -4.4042e-02, -3.5150e+00, -1.3722e-01,\n",
            "        -1.5593e+00, -4.4365e-01,  6.8929e-01,  2.5315e+00, -1.7920e+00,\n",
            "        -5.4836e-01, -7.1692e-01,  3.5433e-01,  2.0494e+00, -2.1104e+00,\n",
            "         8.7708e-01, -3.0147e+00, -1.8875e+00, -2.6837e+00,  6.4305e-01,\n",
            "        -1.0913e+00,  7.6610e-01,  1.3402e+00, -2.2022e+00,  6.1311e-01,\n",
            "         9.0442e-01, -4.1323e-01, -3.4455e-01,  1.1483e+00,  1.5898e+00,\n",
            "        -1.8610e+00,  4.9357e+00,  5.3825e-01,  7.7787e-01, -3.8756e+00,\n",
            "         2.6219e+00,  4.3165e-01, -2.2180e-01, -4.9105e-01,  3.9985e-01,\n",
            "        -3.9724e+00, -2.7648e+00, -4.2280e+00, -1.5722e+00, -5.8195e-01,\n",
            "        -2.9077e+00, -2.7884e+00, -1.2227e+00,  4.8205e-01, -7.4056e-01,\n",
            "        -9.4565e-01,  1.0145e-01,  5.2493e-01, -1.3142e+00,  3.8593e-01,\n",
            "         1.2715e+00, -2.1164e+00, -2.6718e-01,  2.3715e+00,  1.9753e-01,\n",
            "        -1.1598e+00, -3.3297e-01, -6.5732e-01, -6.7085e-01, -4.8066e-01,\n",
            "        -1.0699e+00, -2.0677e+00, -1.3368e+00, -6.3748e-01,  2.5641e-01,\n",
            "        -9.7196e-01,  2.0327e+00, -1.1344e+00,  1.0930e+00,  1.2649e+00,\n",
            "         6.4547e-01, -3.1530e-01,  2.7368e+00,  3.1215e+00, -5.1248e-01,\n",
            "         3.8822e-01, -3.7516e+00, -1.6625e+00,  1.4208e+00, -1.1240e+00,\n",
            "        -5.9586e-01,  2.8028e+00,  1.1084e-01,  6.8404e-01, -3.4109e+00,\n",
            "        -9.9216e-01, -8.4244e-01, -7.0517e-02, -1.2082e+00, -3.1789e+00,\n",
            "         1.3783e+00, -3.5504e-01,  1.1234e+00, -2.6026e+00,  5.1251e-01,\n",
            "         6.0310e-03, -2.0999e+00, -1.3560e+00, -9.7923e-01,  1.6232e+00,\n",
            "         7.1751e-01, -9.6550e-01, -1.1549e+00, -8.5243e-01, -3.0181e-01,\n",
            "        -1.0821e+00,  1.2044e+00,  2.3943e-01,  1.3916e+00,  1.7122e-01,\n",
            "         1.1256e-01,  2.3548e+00, -1.6994e+00,  2.8395e+00,  1.4517e+00,\n",
            "         1.6934e+00,  4.3898e-01, -1.4202e+00,  3.4613e+00,  1.7582e+00,\n",
            "         1.3556e+00, -1.3273e+00, -1.6091e-01, -1.1689e+00,  8.8489e-02,\n",
            "        -5.2617e-01, -9.0804e-01, -3.1413e-01,  2.4310e-01,  7.2142e-01,\n",
            "        -2.0801e+00,  6.6024e-03,  1.4045e+00,  7.6521e-01,  1.5180e+00,\n",
            "        -1.2408e+00, -6.5852e-01,  4.5430e-01, -7.7553e-01, -3.7601e-01,\n",
            "         7.2537e-01,  8.7978e-01,  1.8762e+00,  1.1671e+00, -2.0675e+00,\n",
            "        -1.8731e+00, -5.9325e-01,  1.8245e+00, -8.9375e-01,  1.1804e+00,\n",
            "        -1.1460e+00, -1.4371e+00, -2.1167e+00, -1.9027e+00, -2.3738e+00,\n",
            "         3.7437e+00,  1.2373e+00, -6.7176e-01,  1.1384e+00, -1.9736e+00,\n",
            "        -1.0625e+00,  2.8758e+00, -1.8442e+00,  1.3789e+00, -1.5568e+00,\n",
            "        -1.6640e+00,  1.8345e-01, -1.2826e+00,  7.2640e-01, -8.6114e-01,\n",
            "        -4.1578e-01, -2.5582e+00, -1.0692e+00,  1.2787e+00, -5.6225e-01,\n",
            "         9.8428e-01,  5.7149e-01,  1.9032e+00,  4.2216e-01, -3.0862e+00,\n",
            "        -2.8035e-01, -2.9379e-01, -9.9284e-01, -6.6972e-01, -1.4468e+00,\n",
            "         1.5195e+00,  5.2939e-01,  9.7532e-01, -8.3155e-01,  3.0828e-01,\n",
            "         1.0107e+00, -1.2643e-01,  7.3332e-01, -5.8430e-03, -3.0136e+00,\n",
            "         1.0316e+00, -1.6334e+00, -2.1181e+00, -8.9552e-01, -1.2334e+00,\n",
            "         2.0469e+00,  2.7116e+00,  5.5917e+00,  2.9906e-03, -2.6829e+00,\n",
            "        -7.4086e-01, -1.2430e+00, -2.0210e+00, -7.7245e-01, -5.0100e-02,\n",
            "        -1.6353e+00,  6.5280e-01, -5.5977e-02,  4.3358e-01, -1.3729e+00,\n",
            "        -7.0142e-01, -1.0914e+00, -2.2620e+00, -5.5622e-01, -1.1686e+00,\n",
            "         9.1277e-01, -1.9311e+00,  1.7694e+00, -1.3642e+00, -5.3308e+00,\n",
            "        -1.1081e+00,  1.1822e+00, -1.4822e+00, -1.7938e+00,  1.7585e+00,\n",
            "         1.8221e+00,  1.1336e+00,  1.7776e+00, -3.6183e+00, -4.4536e+00,\n",
            "        -1.3719e+00, -1.6941e+00, -3.7143e+00, -2.2348e-01,  3.2542e-01,\n",
            "        -2.2640e+00, -2.0380e-01, -3.4624e-01, -3.3129e+00, -1.6491e+00,\n",
            "        -2.9339e+00, -1.7346e+00,  2.3053e-01,  1.4986e+00,  7.5267e-01,\n",
            "        -1.4457e+00, -3.1856e-01,  1.6376e+00, -1.7135e+00,  2.8956e-01,\n",
            "        -1.1813e+00, -7.5507e-01, -5.4260e-01, -2.0891e+00,  3.9697e-01,\n",
            "         7.0728e-01,  1.6597e-01, -2.8241e-02,  1.3085e-01, -2.0410e+00,\n",
            "         1.8595e+00,  8.4186e-02, -2.1861e+00,  6.2103e-01, -2.6136e+00,\n",
            "        -1.3786e+00, -3.4561e-01, -2.3958e+00, -2.7693e+00,  6.3648e-01,\n",
            "        -3.4256e+00, -2.4249e+00,  3.4585e-01, -4.0787e+00,  2.5888e+00,\n",
            "        -1.2227e+00, -1.6819e+00,  1.6968e+00, -2.9695e+00,  8.5958e-01,\n",
            "         9.2511e-01,  2.2052e+00,  1.6521e+00,  9.9418e-01,  1.3037e+00,\n",
            "         8.7367e-01,  1.0198e-02,  3.0090e+00,  1.0823e+00, -1.6916e+00,\n",
            "        -2.0653e+00, -1.8346e+00, -3.2477e-01,  2.6213e+00,  1.1798e+00,\n",
            "         2.9327e-01, -5.3164e-01,  2.0278e-01, -3.8829e-01,  1.6185e+00,\n",
            "         9.2775e-01,  1.8160e-01,  1.3443e+00,  1.4627e+00, -1.7995e+00,\n",
            "        -2.4594e+00, -5.6864e-01, -7.5154e-01, -1.9544e+00, -2.7460e+00,\n",
            "        -1.6502e+00,  5.7471e-01, -4.0912e+00,  1.9556e+00,  1.0564e+00,\n",
            "         2.6655e-01,  3.4312e+00, -2.3619e+00, -2.3434e+00, -7.8953e-01,\n",
            "         5.1805e-01, -9.1223e-01, -2.1092e+00, -1.0572e+00, -4.4546e-01,\n",
            "        -1.8325e+00, -2.4435e+00, -2.4947e-01, -2.1455e+00,  1.1313e+00,\n",
            "        -1.4004e-01, -1.0403e+00,  2.6821e+00,  1.7739e+00,  4.8442e-01,\n",
            "         4.1989e+00,  2.1025e+00,  2.5615e+00, -1.6331e+00,  1.0295e+00,\n",
            "         4.2965e-02,  1.1865e+00,  1.2651e+00,  7.9414e-01,  2.8179e-01],\n",
            "       device='cuda:0')\n",
            "tensor([1.6879e-06, 1.8647e-07, 1.1665e-07, 1.8448e-08, 2.4313e-07, 1.4512e-07,\n",
            "        3.0017e-07, 3.4414e-06, 5.6798e-05, 3.2356e-08, 8.6886e-08, 4.2655e-07,\n",
            "        3.4255e-07, 2.7741e-07, 8.4761e-07, 5.5587e-08, 8.7880e-08, 1.6346e-06,\n",
            "        1.6704e-06, 1.3500e-06, 3.8063e-07, 2.8268e-07, 4.7811e-07, 1.1522e-06,\n",
            "        3.9000e-07, 1.3033e-06, 9.2778e-07, 2.7082e-06, 1.3762e-06, 1.7881e-06,\n",
            "        2.7835e-07, 7.9006e-08, 4.4165e-07, 2.0611e-07, 3.9038e-07, 2.7940e-06,\n",
            "        2.9372e-05, 2.3336e-05, 1.8987e-07, 9.2645e-07, 3.8549e-07, 1.2818e-07,\n",
            "        9.2087e-07, 1.8335e-06, 1.1466e-06, 3.7044e-07, 9.7874e-07, 3.4822e-07,\n",
            "        8.9715e-07, 5.6453e-07, 7.0245e-07, 5.3381e-07, 2.1330e-06, 1.0113e-06,\n",
            "        1.8996e-06, 5.4857e-07, 1.2537e-06, 4.9736e-07, 1.2568e-07, 5.8080e-07,\n",
            "        1.1343e-06, 2.7105e-07, 8.1819e-07, 9.8732e-07, 8.3652e-07, 2.8255e-07,\n",
            "        4.0368e-07, 7.7723e-07, 3.7570e-07, 3.3736e-08, 1.0517e-07, 1.2917e-07,\n",
            "        9.4373e-08, 1.2068e-07, 4.7685e-08, 3.9308e-08, 2.7438e-08, 1.5938e-07,\n",
            "        2.7405e-06, 5.9154e-07, 1.4878e-06, 1.8604e-05, 7.8516e-06, 9.7985e-07,\n",
            "        2.6699e-06, 1.2992e-06, 2.2974e-06, 2.8549e-07, 1.2651e-07, 6.0458e-06,\n",
            "        3.5664e-07, 1.7837e-07, 7.1102e-08, 7.1625e-07, 1.6351e-07, 5.9558e-08,\n",
            "        1.3027e-06, 1.3548e-07, 3.8666e-07, 6.5485e-07, 5.0518e-06, 5.0092e-07,\n",
            "        1.0820e-06, 6.5404e-07, 8.8568e-05, 3.5742e-07, 4.3504e-06, 1.1087e-07,\n",
            "        8.2528e-07, 9.1353e-08, 2.3409e-07, 1.1293e-08, 1.9839e-06, 3.5601e-07,\n",
            "        1.3000e-05, 5.8028e-07, 6.2981e-08, 4.2239e-07, 3.4676e-07, 1.4771e-07,\n",
            "        2.3389e-07, 2.7316e-07, 8.3910e-07, 1.6876e-07, 6.4618e-06, 1.5062e-07,\n",
            "        3.0398e-07, 1.1097e-06, 2.0215e-07, 2.4724e-06, 2.5425e-07, 2.3368e-07,\n",
            "        1.7371e-06, 1.2476e-07, 1.8263e-06, 1.0285e-06, 3.0356e-07, 6.1067e-07,\n",
            "        2.0353e-07, 5.5855e-07, 2.9291e-07, 1.5255e-07, 7.3563e-08, 8.8875e-07,\n",
            "        2.7949e-07, 8.5170e-06, 2.5505e-06, 5.6576e-08, 4.5022e-08, 8.4569e-07,\n",
            "        6.0631e-08, 7.0771e-05, 9.7248e-05, 4.2381e-05, 7.3606e-05, 7.7504e-07,\n",
            "        9.3786e-07, 1.1382e-03, 1.0763e-06, 4.4669e-07, 1.3008e-05, 5.3228e-08,\n",
            "        3.5866e-08, 6.8011e-07, 3.0583e-07, 3.1921e-08, 2.8689e-07, 1.6945e-07,\n",
            "        1.2334e-06, 1.8533e-05, 1.1943e-05, 3.2860e-07, 2.4503e-07, 4.6916e-06,\n",
            "        4.1264e-05, 6.4154e-06, 2.8986e-07, 2.2342e-06, 2.3240e-07, 2.8459e-06,\n",
            "        6.5183e-06, 1.2501e-06, 1.4162e-07, 5.1308e-06, 1.8806e-06, 1.2472e-04,\n",
            "        4.8069e-04, 1.2815e-06, 5.3457e-06, 1.3707e-06, 5.6176e-05, 4.9785e-08,\n",
            "        5.6287e-05, 3.0098e-04, 3.8317e-05, 5.8292e-07, 6.6335e-07, 7.5184e-06,\n",
            "        6.9406e-07, 6.5457e-05, 5.0498e-05, 3.0237e-06, 5.4505e-06, 1.9696e-03,\n",
            "        2.6625e-05, 3.4534e-07, 7.5392e-07, 1.7369e-05, 4.6748e-07, 2.7624e-07,\n",
            "        4.6850e-08, 1.2207e-07, 4.4195e-06, 1.1017e-06, 1.3392e-06, 7.1227e-07,\n",
            "        7.1686e-05, 6.2085e-07, 1.6028e-06, 2.8262e-06, 4.3678e-06, 4.2884e-06,\n",
            "        1.3675e-03, 7.2950e-04, 9.1608e-04, 7.4367e-07, 6.2035e-05, 3.6187e-06,\n",
            "        1.0289e-04, 1.9052e-04, 5.3478e-04, 1.2755e-03, 1.2944e-03, 3.7509e-05,\n",
            "        4.3846e-07, 3.0375e-05, 2.5528e-06, 4.2615e-07, 9.9877e-07, 5.3480e-06,\n",
            "        4.0382e-06, 7.0658e-06, 2.2751e-07, 2.3502e-07, 2.2641e-05, 1.1977e-06,\n",
            "        3.6076e-07, 5.5994e-06, 5.7025e-03, 1.1059e-03, 5.4447e-04, 1.8554e-06,\n",
            "        3.5454e-06, 3.4428e-07, 5.2003e-08, 3.2233e-05, 9.2978e-05, 7.1883e-03,\n",
            "        7.9647e-01, 4.9240e-02, 2.5329e-03, 1.2470e-02, 2.4559e-07, 1.2557e-04,\n",
            "        1.9466e-04, 8.4431e-06, 4.9485e-05, 2.5066e-05, 6.0700e-07, 1.4411e-04,\n",
            "        2.1286e-02, 2.0422e-05, 1.1684e-05, 7.9377e-06, 9.4877e-05, 2.6743e-06,\n",
            "        5.7665e-06, 3.8793e-05, 4.2350e-05, 8.7027e-02, 6.3199e-05, 5.1679e-06,\n",
            "        3.9637e-06, 2.3276e-04, 1.6678e-06, 3.8142e-07, 1.5287e-07, 7.8414e-05,\n",
            "        2.5541e-08, 3.2619e-06, 9.8987e-08, 3.4777e-06, 2.1672e-06, 9.0947e-07,\n",
            "        1.9738e-06, 1.2681e-06, 8.5136e-06, 5.3654e-06, 1.2624e-06, 1.7156e-07,\n",
            "        2.7107e-08, 5.7383e-07, 1.6110e-07, 1.5301e-07, 1.7614e-07, 3.3010e-07,\n",
            "        9.1392e-07, 1.3533e-07, 3.8993e-09, 6.9327e-08, 3.3795e-07, 9.3246e-08,\n",
            "        6.1837e-07, 1.2332e-07, 1.0011e-06, 3.7357e-08, 4.7995e-07, 1.6427e-07,\n",
            "        2.8893e-07, 2.1832e-08, 4.1259e-08, 1.5489e-08, 3.1440e-08, 1.1481e-06,\n",
            "        1.0010e-06, 2.2800e-07, 6.2294e-08, 1.6925e-07, 1.5031e-07, 4.2882e-07,\n",
            "        8.1847e-06, 2.3928e-05, 1.0566e-03, 1.5929e-05, 9.7773e-06, 8.4689e-06,\n",
            "        1.8991e-05, 6.5162e-06, 7.4172e-06, 2.2169e-08, 1.1368e-07, 2.5426e-06,\n",
            "        8.4005e-07, 5.8205e-08, 5.7470e-08, 2.4406e-07, 7.3172e-08, 2.0416e-08,\n",
            "        1.1325e-06, 1.0484e-07, 4.5734e-07, 1.0166e-08, 1.2745e-08, 1.0931e-07,\n",
            "        6.0347e-08, 6.0874e-06, 9.5256e-05, 2.1653e-05, 1.1380e-04, 3.9999e-05,\n",
            "        3.1606e-07, 2.7141e-04, 1.2540e-05, 1.7853e-06, 2.6590e-07, 7.7194e-08,\n",
            "        6.7596e-08, 9.1913e-08, 4.9089e-06, 8.8555e-07, 5.6594e-07, 2.7856e-06,\n",
            "        4.7716e-07, 4.7742e-06, 1.5659e-06, 8.1173e-07, 2.0034e-07, 1.5224e-05,\n",
            "        2.4721e-06, 3.9181e-07, 1.2620e-05, 3.1169e-07, 2.1474e-06, 9.4697e-06,\n",
            "        1.0167e-05, 6.7391e-08, 4.9240e-08, 3.6006e-06, 5.0669e-06, 1.3801e-06,\n",
            "        1.7881e-07, 2.6435e-06, 4.1002e-08, 8.8243e-08, 1.5978e-07, 1.9607e-07,\n",
            "        1.0182e-07, 9.1351e-08, 3.3849e-07, 5.6585e-08, 1.5101e-07, 2.7728e-06,\n",
            "        9.0713e-07, 9.8685e-08, 9.3719e-08, 3.6518e-07, 1.5940e-07, 1.7725e-07,\n",
            "        3.1133e-06, 3.6223e-06, 7.8980e-07, 1.0451e-07, 7.9568e-06, 1.2926e-05,\n",
            "        1.6149e-07, 7.5909e-08, 1.1487e-06, 1.0286e-07, 7.3842e-07, 3.5070e-06,\n",
            "        5.9507e-06, 7.4617e-08, 1.3477e-07, 1.1484e-07, 3.2604e-09, 1.3872e-07,\n",
            "        5.8450e-07, 1.2375e-06, 2.9066e-05, 9.0529e-06, 3.6112e-08, 1.3682e-06,\n",
            "        2.7405e-07, 1.2350e-07, 2.7154e-07, 1.1782e-06, 3.0492e-07, 1.3001e-06,\n",
            "        9.0110e-08, 6.6670e-07, 2.6719e-05, 6.9174e-07, 1.2780e-07, 1.2541e-06,\n",
            "        6.6727e-07, 9.2229e-07, 1.6026e-08, 2.1936e-06, 1.2785e-06, 1.3048e-07,\n",
            "        1.9625e-07, 1.7635e-07, 5.7399e-06, 1.6550e-07, 7.5265e-08, 3.0536e-06,\n",
            "        2.3146e-06, 6.0270e-06, 6.3583e-07, 5.9689e-07, 8.6628e-07, 2.9581e-07,\n",
            "        6.4216e-06, 1.3379e-05, 9.0082e-08, 8.4313e-07, 5.2814e-08, 5.0391e-07,\n",
            "        1.1169e-07, 2.2743e-06, 6.4733e-07, 4.1759e-06, 7.2392e-06, 1.1347e-06,\n",
            "        1.5932e-07, 3.8461e-07, 9.4374e-09, 1.7708e-07, 1.2224e-06, 4.2491e-07,\n",
            "        1.0403e-07, 4.6188e-08, 7.8173e-07, 9.4407e-08, 1.0827e-07, 1.5714e-07,\n",
            "        4.5057e-07, 2.6730e-06, 1.4688e-06, 9.8492e-07, 4.4194e-06, 3.9937e-06,\n",
            "        9.9897e-07, 3.8209e-07, 1.0170e-06, 1.1820e-07, 9.6130e-06, 3.2281e-07,\n",
            "        1.3671e-08, 4.3994e-06, 2.3132e-08, 5.4276e-06, 5.4507e-06, 1.6577e-07,\n",
            "        3.5378e-07, 5.1920e-07, 2.8082e-07, 5.3036e-07, 1.0935e-06, 1.5712e-08,\n",
            "        2.9195e-07, 4.4794e-07, 8.7298e-08, 1.2940e-07, 3.4056e-06, 2.9697e-06,\n",
            "        4.0847e-07, 7.6305e-08, 1.5890e-06, 2.2655e-06, 3.3814e-08, 8.5769e-07,\n",
            "        2.8184e-05, 2.5807e-06, 2.2046e-07, 1.0205e-07, 2.5244e-07, 4.5505e-07,\n",
            "        2.8364e-07, 4.4690e-06, 1.1743e-06, 2.0450e-07, 5.6354e-08, 1.6950e-07,\n",
            "        3.8826e-06, 1.7773e-08, 4.0391e-08, 9.5659e-07, 8.7522e-08, 1.3446e-05,\n",
            "        1.0105e-07, 2.1550e-07, 3.7874e-07, 6.3089e-06, 1.3276e-06, 6.1314e-06,\n",
            "        3.3639e-07, 1.5425e-08, 2.8411e-07, 6.5527e-07, 1.6203e-08, 8.6495e-08,\n",
            "        1.2557e-05, 1.5649e-07, 6.2318e-07, 7.7726e-08, 9.2159e-07, 5.2012e-07,\n",
            "        1.0754e-06, 1.2301e-06, 1.2813e-06, 3.7758e-07, 9.1841e-08, 2.2243e-07,\n",
            "        1.6530e-07, 7.0573e-08, 6.2326e-07, 5.0385e-06, 1.3632e-06, 2.0281e-07,\n",
            "        3.4724e-07, 2.6582e-08, 1.6668e-07, 1.6229e-07, 7.0581e-06, 2.3684e-06,\n",
            "        1.7326e-08, 3.6628e-07, 8.9131e-07, 3.9890e-07, 1.4191e-06, 3.7151e-08,\n",
            "        4.4873e-07, 2.4608e-07, 1.1607e-07, 9.4180e-08, 1.6396e-07, 2.6319e-06,\n",
            "        1.0357e-06, 3.4941e-06, 1.9024e-07, 1.4213e-06, 1.0964e-08, 1.2037e-06,\n",
            "        3.5227e-06, 1.5584e-07, 1.7979e-05, 8.8089e-08, 1.2135e-06, 2.4579e-07,\n",
            "        9.3974e-07, 9.1971e-07, 1.5606e-07, 7.9649e-08, 6.8575e-08, 6.1714e-07,\n",
            "        1.0125e-06, 8.8819e-07, 3.0912e-07, 2.0790e-07, 2.2120e-06, 5.3357e-06,\n",
            "        1.5661e-08, 6.1882e-07, 6.1326e-08, 8.7955e-07, 6.1464e-08, 1.5680e-07,\n",
            "        1.7809e-06, 4.2703e-08, 6.5984e-07, 1.5408e-05, 8.5519e-06, 3.4658e-07,\n",
            "        1.9555e-08, 7.7385e-08, 2.5715e-06, 3.2782e-07, 1.8673e-07, 1.7145e-07,\n",
            "        1.8951e-06, 7.0253e-07, 2.6515e-07, 6.7542e-07, 2.6037e-07, 1.2182e-06,\n",
            "        6.9962e-08, 4.0809e-06, 2.9179e-07, 5.2404e-07, 2.4392e-06, 3.6619e-06,\n",
            "        1.0733e-06, 1.0529e-07, 1.5187e-06, 1.3713e-06, 1.0603e-05, 7.6867e-07,\n",
            "        2.3896e-08, 7.0028e-07, 1.6891e-07, 5.1546e-07, 1.6004e-06, 1.0099e-05,\n",
            "        1.3385e-07, 4.6421e-07, 3.9220e-07, 1.1448e-06, 6.2362e-06, 9.7345e-08,\n",
            "        1.9310e-06, 3.9410e-08, 1.2165e-07, 5.4871e-08, 1.5280e-06, 2.6972e-07,\n",
            "        1.7281e-06, 3.0682e-06, 8.8811e-08, 1.4830e-06, 1.9845e-06, 5.3138e-07,\n",
            "        5.6915e-07, 2.5326e-06, 3.9382e-06, 1.2492e-07, 1.1180e-04, 1.3760e-06,\n",
            "        1.7486e-06, 1.6661e-08, 1.1055e-05, 1.2369e-06, 6.4348e-07, 4.9159e-07,\n",
            "        1.1982e-06, 1.5125e-08, 5.0597e-08, 1.1713e-08, 1.6676e-07, 4.4887e-07,\n",
            "        4.3862e-08, 4.9417e-08, 2.3651e-07, 1.3008e-06, 3.8304e-07, 3.1201e-07,\n",
            "        8.8905e-07, 1.3578e-06, 2.1582e-07, 1.1816e-06, 2.8648e-06, 9.6765e-08,\n",
            "        6.1493e-07, 8.6054e-06, 9.7870e-07, 2.5186e-07, 5.7578e-07, 4.1629e-07,\n",
            "        4.1070e-07, 4.9673e-07, 2.7557e-07, 1.0160e-07, 2.1102e-07, 4.2463e-07,\n",
            "        1.0381e-06, 3.0391e-07, 6.1325e-06, 2.5835e-07, 2.3963e-06, 2.8457e-06,\n",
            "        1.5317e-06, 5.8604e-07, 1.2400e-05, 1.8218e-05, 4.8117e-07, 1.1843e-06,\n",
            "        1.8862e-08, 1.5235e-07, 3.3259e-06, 2.6105e-07, 4.4267e-07, 1.3246e-05,\n",
            "        8.9743e-07, 1.5920e-06, 2.6517e-08, 2.9783e-07, 3.4594e-07, 7.4858e-07,\n",
            "        2.3997e-07, 3.3442e-08, 3.1876e-06, 5.6321e-07, 2.4702e-06, 5.9507e-08,\n",
            "        1.3410e-06, 8.0814e-07, 9.8376e-08, 2.0700e-07, 3.0171e-07, 4.0722e-06,\n",
            "        1.6462e-06, 3.0588e-07, 2.5311e-07, 3.4250e-07, 5.9401e-07, 2.7223e-07,\n",
            "        2.6789e-06, 1.0206e-06, 3.2302e-06, 9.5329e-07, 8.9898e-07, 8.4634e-06,\n",
            "        1.4683e-07, 1.3742e-05, 3.4301e-06, 4.3681e-06, 1.2460e-06, 1.9412e-07,\n",
            "        2.5591e-05, 4.6605e-06, 3.1160e-06, 2.1303e-07, 6.8388e-07, 2.4957e-07,\n",
            "        8.7760e-07, 4.7463e-07, 3.2397e-07, 5.8673e-07, 1.0243e-06, 1.6526e-06,\n",
            "        1.0034e-07, 8.0860e-07, 3.2723e-06, 1.7266e-06, 3.6656e-06, 2.3227e-07,\n",
            "        4.1579e-07, 1.2652e-06, 3.6988e-07, 5.5153e-07, 1.6592e-06, 1.9362e-06,\n",
            "        5.2443e-06, 2.5808e-06, 1.0162e-07, 1.2342e-07, 4.4383e-07, 4.9801e-06,\n",
            "        3.2863e-07, 2.6152e-06, 2.5537e-07, 1.9087e-07, 9.6739e-08, 1.1982e-07,\n",
            "        7.4808e-08, 3.3941e-05, 2.7682e-06, 4.1032e-07, 2.5077e-06, 1.1162e-07,\n",
            "        2.7761e-07, 1.4249e-05, 1.2704e-07, 3.1893e-06, 1.6934e-07, 1.5213e-07,\n",
            "        9.6502e-07, 2.2275e-07, 1.6609e-06, 3.3953e-07, 5.3002e-07, 6.2207e-08,\n",
            "        2.7575e-07, 2.8853e-06, 4.5781e-07, 2.1495e-06, 1.4225e-06, 5.3879e-06,\n",
            "        1.2252e-06, 3.6690e-08, 6.0689e-07, 5.9879e-07, 2.9763e-07, 4.1116e-07,\n",
            "        1.8903e-07, 3.6710e-06, 1.3639e-06, 2.1303e-06, 3.4973e-07, 1.0933e-06,\n",
            "        2.2070e-06, 7.0788e-07, 1.6724e-06, 7.9860e-07, 3.9453e-08, 2.2537e-06,\n",
            "        1.5685e-07, 9.6602e-08, 3.2805e-07, 2.3399e-07, 6.2205e-06, 1.2092e-05,\n",
            "        2.1544e-04, 8.0568e-07, 5.4917e-08, 3.8293e-07, 2.3175e-07, 1.0645e-07,\n",
            "        3.7102e-07, 7.6402e-07, 1.5656e-07, 1.5430e-06, 7.5955e-07, 1.2393e-06,\n",
            "        2.0353e-07, 3.9833e-07, 2.6969e-07, 8.3653e-08, 4.6058e-07, 2.4967e-07,\n",
            "        2.0011e-06, 1.1647e-07, 4.7132e-06, 2.0531e-07, 3.8882e-09, 2.6522e-07,\n",
            "        2.6199e-06, 1.8245e-07, 1.3361e-07, 4.6621e-06, 4.9680e-06, 2.4957e-06,\n",
            "        4.7520e-06, 2.1550e-08, 9.3473e-09, 2.0374e-07, 1.4762e-07, 1.9579e-08,\n",
            "        6.4241e-07, 1.1122e-06, 8.3484e-08, 6.5517e-07, 5.6819e-07, 2.9247e-08,\n",
            "        1.5441e-07, 4.2724e-08, 1.4176e-07, 1.0115e-06, 3.5950e-06, 1.7051e-06,\n",
            "        1.8925e-07, 5.8414e-07, 4.1313e-06, 1.4478e-07, 1.0730e-06, 2.4651e-07,\n",
            "        3.7752e-07, 4.6689e-07, 9.9449e-08, 1.1947e-06, 1.6294e-06, 9.4830e-07,\n",
            "        7.8091e-07, 9.1558e-07, 1.0435e-07, 5.1576e-06, 8.7383e-07, 9.0251e-08,\n",
            "        1.4948e-06, 5.8856e-08, 2.0236e-07, 5.6855e-07, 7.3179e-08, 5.0369e-08,\n",
            "        1.5180e-06, 2.6131e-08, 7.1083e-08, 1.1352e-06, 1.3599e-08, 1.0695e-05,\n",
            "        2.3652e-07, 1.4942e-07, 4.3832e-06, 4.1231e-08, 1.8975e-06, 2.0260e-06,\n",
            "        7.2874e-06, 4.1914e-06, 2.1709e-06, 2.9582e-06, 1.9244e-06, 8.1151e-07,\n",
            "        1.6280e-05, 2.3709e-06, 1.4799e-07, 1.0184e-07, 1.2826e-07, 5.8052e-07,\n",
            "        1.1048e-05, 2.6137e-06, 1.0770e-06, 4.7204e-07, 9.8385e-07, 5.4480e-07,\n",
            "        4.0529e-06, 2.0313e-06, 9.6323e-07, 3.0809e-06, 3.4684e-06, 1.3285e-07,\n",
            "        6.8671e-08, 4.5489e-07, 3.7886e-07, 1.1379e-07, 5.1557e-08, 1.5424e-07,\n",
            "        1.4271e-06, 1.3431e-08, 5.6775e-06, 2.3103e-06, 1.0486e-06, 2.4833e-05,\n",
            "        7.5702e-08, 7.7118e-08, 3.6473e-07, 1.3485e-06, 3.2262e-07, 9.7462e-08,\n",
            "        2.7909e-07, 5.1452e-07, 1.2853e-07, 6.9771e-08, 6.2592e-07, 9.3995e-08,\n",
            "        2.4899e-06, 6.9831e-07, 2.8383e-07, 1.1740e-05, 4.7345e-06, 1.3039e-06,\n",
            "        5.3510e-05, 6.5758e-06, 1.0406e-05, 1.5690e-07, 2.2488e-06, 8.3854e-07,\n",
            "        2.6312e-06, 2.8464e-06, 1.7773e-06, 1.0647e-06], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CobrFet0xDTh"
      },
      "source": [
        "### Model Description\n",
        "This project includes the semi-supervised and semi-weakly supervised ImageNet models introduced in \"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>.\n",
        "\n",
        "\"Semi-supervised\" (SSL) ImageNet models are pre-trained on a subset of unlabeled YFCC100M public image dataset and fine-tuned with the ImageNet1K training dataset, as described by the semi-supervised training framework in the paper mentioned above. In this case, the high capacity teacher model was trained only with labeled examples.\n",
        "\n",
        "\"Semi-weakly\" supervised (SWSL) ImageNet models are pre-trained on **940 million** public images with 1.5K hashtags matching with 1000 ImageNet1K synsets, followed by fine-tuning on ImageNet1K dataset. In this case, the associated hashtags are only used for building a better teacher model. During training the student model, those hashtags are ingored and the student model is pretrained with a subset of 64M images selected by the teacher model from the same 940 million public image dataset.\n",
        "\n",
        "Semi-weakly supervised ResNet and ResNext models provided in the table below significantly improve the top-1 accuracy on the ImageNet validation set compared to training from scratch or other training mechanisms introduced in the literature as of September 2019. For example, **We achieve state-of-the-art accuracy of 81.2% on ImageNet for the widely used/adopted ResNet-50 model architecture**.\n",
        "\n",
        "\n",
        "| Architecture       |   Supervision   | #Parameters | FLOPS | Top-1 Acc. | Top-5 Acc. |\n",
        "| ------------------ | :--------------:|:----------: | :---: | :--------: | :--------: |\n",
        "| ResNet-18          | semi-supervised        |14M     | 2B   |     72.8      | 91.5    |\n",
        "| ResNet-50          | semi-supervised        |25M     | 4B   |     79.3      | 94.9    |\n",
        "| ResNeXt-50 32x4d   | semi-supervised        |25M     | 4B   |     80.3      | 95.4    |\n",
        "| ResNeXt-101 32x4d  | semi-supervised        |42M     | 8B   |     81.0      | 95.7    |\n",
        "| ResNeXt-101 32x8d  | semi-supervised        |88M     | 16B   |     81.7    |  96.1   |\n",
        "| ResNeXt-101 32x16d | semi-supervised        |193M    | 36B   |     81.9   | 96.2     |\n",
        "| ResNet-18          | semi-weakly supervised |14M     | 2B   |    **73.4**    |  91.9      |\n",
        "| ResNet-50          | semi-weakly supervised |25M     | 4B   |    **81.2**    |  96.0      |\n",
        "| ResNeXt-50 32x4d   | semi-weakly supervised |25M     | 4B   |    **82.2**    |  96.3      |\n",
        "| ResNeXt-101 32x4d  | semi-weakly supervised |42M     | 8B   |    **83.4**    |  96.8      |\n",
        "| ResNeXt-101 32x8d  | semi-weakly supervised |88M     | 16B   |  **84.3**    |  97.2    |\n",
        "| ResNeXt-101 32x16d | semi-weakly supervised |193M    | 36B   |  **84.8**    |  97.4    |\n",
        "\n",
        "\n",
        "## Citation\n",
        "\n",
        "If you use the models released in this repository, please cite the following publication (https://arxiv.org/abs/1905.00546)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0T0hM-FxDTi",
        "outputId": "09a344d1-096d-4232-eed4-aa22db8cfc9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        }
      },
      "source": [
        "@misc{yalniz2019billionscale,\n",
        "    title={Billion-scale semi-supervised learning for image classification},\n",
        "    author={I. Zeki Yalniz and Herv Jgou and Kan Chen and Manohar Paluri and Dhruv Mahajan},\n",
        "    year={2019},\n",
        "    eprint={1905.00546},\n",
        "    archivePrefix={arXiv},\n",
        "    primaryClass={cs.CV}\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-63a5fecf9613>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    @misc{yalniz2019billionscale,\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}